# PostgreSQL Transactional Outbox

[![MIT License](https://img.shields.io/badge/license-MIT-blue.svg)](LICENSE)
[![TypeScript](https://img.shields.io/badge/TypeScript-5.3-blue.svg)](https://www.typescriptlang.org/)
[![PostgreSQL](https://img.shields.io/badge/PostgreSQL-15+-blue.svg)](https://www.postgresql.org/)

> **Production-grade Transactional Outbox Framework** for guaranteed event delivery with PostgreSQL.

### üìö Documenta√ß√£o / Documentation
- [üìñ **Manual de Uso (Portugu√™s)**](docs/USAGE_GUIDE.md)
- [üìñ **Architecture Reference (English)**](#üèóÔ∏è-architecture)

## üéØ Why Transactional Outbox?

### The Dual-Write Problem

```
‚ùå WRONG: Two separate writes that can fail independently

BEGIN;
  INSERT INTO orders (...);  -- ‚úÖ Succeeds
COMMIT;

await kafka.publish(event);  -- ‚ùå Fails (network error)
-- Result: Order created, but no event published!
```

### The Outbox Solution

```
‚úÖ RIGHT: Single atomic transaction

BEGIN;
  INSERT INTO orders (...);       -- Business state
  INSERT INTO outbox (...);       -- Event (same TX!)
COMMIT;

-- Worker picks up and publishes later
-- Even if Kafka is down, event is durably stored
```

## üèóÔ∏è Architecture

This framework implements the **Transactional Outbox Pattern** with:

- **At-Least-Once Delivery**: Events are guaranteed to be published
- **Idempotency Contract**: Consumers MUST handle duplicates
- **Lease/Heartbeat**: Prevents zombie workers
- **Reaper Process**: Recovers stale events
- **Dead Letter Events (DLE)**: Isolates poison messages

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                     APPLICATION                             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê      ‚îÇ
‚îÇ  ‚îÇ  Service    ‚îÇ‚îÄ‚îÄ‚ñ∂ ‚îÇ  Outbox     ‚îÇ‚îÄ‚îÄ‚ñ∂‚îÇ   Worker    ‚îÇ      ‚îÇ
‚îÇ  ‚îÇ  (writes)   ‚îÇ    ‚îÇ  (table)    ‚îÇ    ‚îÇ  (relay)    ‚îÇ      ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò      ‚îÇ
‚îÇ         ‚îÇ                  ‚îÇ                  ‚îÇ             ‚îÇ
‚îÇ         ‚ñº                  ‚ñº                  ‚ñº             ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê  ‚îÇ
‚îÇ  ‚îÇ                     PostgreSQL                        ‚îÇ  ‚îÇ
‚îÇ  ‚îÇ   Same Transaction = Atomicity Guarantee              ‚îÇ  ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
                               ‚îÇ
                               ‚ñº
                    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
                    ‚îÇ External System ‚îÇ
                    ‚îÇ (Kafka, SNS...) ‚îÇ
                    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## ‚ö†Ô∏è Ordering Guarantees

> [!WARNING]
> This library does **NOT** guarantee global event ordering.

**Event order is NOT preserved when:**
- Multiple workers are running (parallelism > 1)
- Events fail and are retried (retry reorders the queue)
- Network partitions cause lease expirations

**If strict ordering is required:**
1. Use single worker mode (`concurrency: 1`)
2. Implement consumer-side ordering (e.g., sequence numbers per aggregate)
3. Consider a partition-aware design (one worker per aggregate)

The library logs a warning when `concurrency > 1` to remind operators of this behavior.

## üì¶ Installation

### Via npm (Recommended)

```bash
npm install pg-transactional-outbox
```

### Via Git (Private/Forked)

```bash
npm install git+ssh://git@github.com:fabioferreccio/pg-transactional-outbox.git
# or
npm install git+https://github.com/fabioferreccio/pg-transactional-outbox.git
```

## üöÄ Release Workflow

To publish a new version (creates git tag & updates package.json):

```bash
# 1. Patch (0.0.X) - Bug fixes
npm run release:patch

# 2. Minor (0.X.0) - New features (backward compatible)
npm run release:minor

# 3. Major (X.0.0) - Breaking changes
npm run release:major
```

## üöÄ Quick Start

### 1. Setup PostgreSQL

```bash
# Start PostgreSQL with optimized settings
docker-compose up -d
```

### 2. Create the Outbox Table (Day 0 Partitioning)

```sql
-- ‚ö†Ô∏è MANDATORY: Table MUST be partitioned from Day 0
CREATE TABLE outbox (
  id              BIGSERIAL,
  tracking_id     UUID NOT NULL DEFAULT gen_random_uuid(),
  aggregate_id    UUID NOT NULL,
  aggregate_type  TEXT NOT NULL,
  event_type      TEXT NOT NULL,
  payload         JSONB NOT NULL,
  metadata        JSONB NOT NULL DEFAULT '{}',
  status          TEXT NOT NULL DEFAULT 'PENDING',
  retry_count     INT NOT NULL DEFAULT 0,
  max_retries     INT NOT NULL DEFAULT 5,
  created_at      TIMESTAMPTZ NOT NULL DEFAULT NOW(),
  processed_at    TIMESTAMPTZ,
  locked_until    TIMESTAMPTZ,
  lock_token      BIGINT,
  last_error      TEXT,
  PRIMARY KEY (id, created_at)
) PARTITION BY RANGE (created_at);

-- Create partitions (pg_partman recommended for automation)
CREATE TABLE outbox_2024_02 PARTITION OF outbox
  FOR VALUES FROM ('2024-02-01') TO ('2024-03-01');
```

### 3. Publish Events (In Same Transaction)

```typescript
import { Pool } from 'pg';
import { PublishEventUseCase, PostgresOutboxRepository } from 'pg-transactional-outbox';

const pool = new Pool({ connectionString: process.env.DATABASE_URL });

// Inside your business transaction
await pool.query('BEGIN');

// 1. Create order (business state)
await pool.query('INSERT INTO orders (id, customer_id, total) VALUES ($1, $2, $3)', 
  [orderId, customerId, total]);

// 2. Publish event (SAME transaction!)
const publishUseCase = new PublishEventUseCase(new PostgresOutboxRepository(pool));
await publishUseCase.execute({
  aggregateId: orderId,
  aggregateType: 'Order',
  eventType: 'OrderCreated',
  payload: { orderId, customerId, total },
});

await pool.query('COMMIT');
```

## üîå Using with ORMs (Prisma, Knex, etc.)

This library is **driver-agnostic**. You can use it with **Prisma**, **Knex**, **TypeORM**, or any other tool by implementing the simple `SqlExecutor` interface.

### Example: Prisma

```typescript
// 1. Create a simple adapter
const prismaExecutor = {
  async query(sql: string, params: any[]) {
    const rows = await prisma.$queryRawUnsafe(sql, ...params);
    return { rows, rowCount: rows.length };
  }
};

// 2. Inject into Repository & Idempotency Store
const repository = new PostgresOutboxRepository(prismaExecutor);
const idempotencyStore = new PostgresIdempotencyStore(prismaExecutor);

// 3. Use inside Prisma Transaction
await prisma.$transaction(async (tx) => {
  const txAdapter = { /* wrapper */ };
  const txRepo = new PostgresOutboxRepository(txAdapter);
  const txIdempotency = new PostgresIdempotencyStore(txAdapter);

  // Check idempotency first!
  if (await txIdempotency.isProcessed(eventId)) return;

  // Process...
  
  // Mark processed
  await txIdempotency.markProcessed(eventId, 'consumer-group');
});
```

üëâ **[See Full Adapter Guide](docs/ORM_ADAPTERS.md)** for Knex, TypeORM, and production-ready code.



## ‚öôÔ∏è Resilience Mechanisms

### Lease / Heartbeat

Events are "leased" to workers for a limited time:

```sql
-- Worker claims events with a lease
UPDATE outbox 
SET status = 'PROCESSING', 
    locked_until = NOW() + INTERVAL '30 seconds',
    lock_token = $1
WHERE status = 'PENDING'
  AND (locked_until IS NULL OR locked_until < NOW())
LIMIT 100
FOR UPDATE SKIP LOCKED
RETURNING *;
```

Workers MUST renew the lease while processing:

```typescript
// Heartbeat every 10 seconds during long operations
const heartbeat = setInterval(async () => {
  await repository.renewLease(eventId, lockToken, 30);
}, 10_000);
```

### Reaper

A background process recovers events "stuck" in PROCESSING:

```sql
-- Reaper query: recover stale events
UPDATE outbox
SET status = 'PENDING',
    locked_until = NULL,
    lock_token = NULL
WHERE status = 'PROCESSING'
  AND locked_until < NOW();  -- lease expired
```

**Rules:**
- Reaper MUST run every `lease_seconds / 2`
- Reaper recovers events with expired leases
- Prevents "zombie workers" from blocking events

### Dead Letter Events (DLE)

Events that fail repeatedly are isolated:

```typescript
// After max retries, event goes to DLE
if (event.retryCount >= event.maxRetries) {
  await repository.markDeadLetter(eventId, lockToken, error);
}
```

**DLE Governance:**
- ‚úÖ Redrive with RCA (Root Cause Analysis) required
- ‚õî Blind redrive is PROHIBITED
- üìä Monitor DLE count as critical metric

## üìã Consumer Contract (MANDATORY)

### ‚ö†Ô∏è Idempotency is NOT Optional

**Every consumer MUST implement deduplication:**

```typescript
// ‚ùå WRONG: No idempotency check
async function handleOrderCreated(event: OrderCreatedEvent) {
  await sendEmail(event.payload.customerId);  // May send twice!
}

// ‚úÖ RIGHT: Idempotent consumer
async function handleOrderCreated(event: OrderCreatedEvent) {
  // 1. Initialize Deduplication Store (supports SqlExecutor!)
  const idempotencyStore = new PostgresIdempotencyStore(poolOrExecutor);

  // 2. Check if already processed
  if (await idempotencyStore.isProcessed(event.trackingId)) {
    return;  // Skip duplicate
  }
  
  // 3. Process event
  await sendEmail(event.payload.customerId);
  
  // 4. Mark as processed (atomically if possible)
  await idempotencyStore.markProcessed(event.trackingId, 'email-service');
}
```

**Why is this mandatory?**
- This is an **at-least-once** delivery system
- Network failures, retries, and Reaper can cause duplicates
- Without idempotency, you WILL process events multiple times

## üìä Partitioning Strategy (Day 0)

### Why Partition from Day 0?

```
‚ùå Problem without partitioning:
- Table grows unbounded
- Vacuum becomes slower over time
- Queries scan entire table
- No way to efficiently archive old data

‚úÖ Solution with partitioning:
- Fast partition pruning on queries
- Independent vacuum per partition
- Easy archival via DETACH
- Bounded data per partition
```

### Retention Tiers

| Tier | Age | Location | Purpose |
|------|-----|----------|---------|
| Hot | 0-7 days | Primary DB | Active processing |
| Warm | 7-90 days | Primary DB | Debugging, audits |
| Cold | 90+ days | Object Storage | Compliance |
| Archived | 1+ year | Glacier/Archive | Legal retention |

### Automated Partition Management

```sql
-- Using pg_partman
SELECT partman.create_parent(
  'public.outbox',
  'created_at',
  'native',
  'daily'
);

-- Enable automatic creation + retention
UPDATE partman.part_config
SET retention = '90 days',
    retention_keep_table = false
WHERE parent_table = 'public.outbox';
```

## üîß Configuration

### PostgreSQL Tuning (docker-compose.yml)

```yaml
command:
  # WAL: Reduce checkpoint frequency
  - "-c" 
  - "max_wal_size=2GB"
  - "-c"
  - "checkpoint_timeout=15min"
  
  # Autovacuum: Aggressive for high-churn tables
  - "-c"
  - "autovacuum_vacuum_scale_factor=0.01"  # 1% instead of 20%
  - "-c"
  - "autovacuum_vacuum_cost_limit=2000"
  
  # Logical replication for CDC
  - "-c"
  - "wal_level=logical"
```

### Environment Variables

```bash
DATABASE_URL=postgresql://user:pass@localhost:5432/outbox
OUTBOX_BATCH_SIZE=100
OUTBOX_LEASE_SECONDS=30
OUTBOX_POLL_INTERVAL_MS=1000
OUTBOX_MAX_RETRIES=5

# Migration Flags (npm run db:migrate):
PARTITION_TABLES=true     # Enable pg_partman
ENABLE_AUDIT=true         # Enable audit triggers
```

## üìà Scale Ceiling

| Throughput | Approach |
|------------|----------|
| < 1,000/s | Single worker, polling |
| 1,000 - 10,000/s | Multiple workers, SKIP LOCKED |
| 10,000 - 50,000/s | pg_notify, aggressive tuning |
| > 50,000/s | **Migrate to Kafka via CDC** |

> ‚ö†Ô∏è **PostgreSQL is not a message broker.** At high scale, use Debezium CDC to stream changes to Kafka.

## üèõÔ∏è Project Structure

```
src/
‚îú‚îÄ‚îÄ core/                    # Hexagonal core (no dependencies)
‚îÇ   ‚îú‚îÄ‚îÄ domain/              # Entities, Value Objects
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ entities/
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ outbox-event.ts
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ value-objects/
‚îÇ   ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ event-status.ts
‚îÇ   ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ trace-context.ts
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ events/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ errors/
‚îÇ   ‚îú‚îÄ‚îÄ ports/               # Interfaces (driven/driver)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ outbox-repository.port.ts
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ event-publisher.port.ts
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ idempotency-store.port.ts
‚îÇ   ‚îî‚îÄ‚îÄ use-cases/           # Application services
‚îÇ       ‚îú‚îÄ‚îÄ publish-event.use-case.ts
‚îÇ       ‚îú‚îÄ‚îÄ process-outbox.use-case.ts
‚îÇ       ‚îî‚îÄ‚îÄ reap-stale-events.use-case.ts
‚îú‚îÄ‚îÄ adapters/                # External implementations
‚îÇ   ‚îî‚îÄ‚îÄ persistence/
‚îÇ       ‚îú‚îÄ‚îÄ postgres-outbox.repository.ts
‚îÇ       ‚îî‚îÄ‚îÄ postgres-idempotency.store.ts
‚îî‚îÄ‚îÄ main/                    # Composition root
    ‚îî‚îÄ‚îÄ index.ts
```

## üìö Resources

### Operational Runbooks

| Document | Purpose |
|----------|---------|
| [DLE Runbook](docs/dle-runbook.md) | Dead Letter handling procedures |
| [Capacity Model](docs/capacity-model.md) | Scale formulas and tuning |
| [Incident Playbook](docs/incident-playbook.md) | Symptom ‚Üí Action mapping |
| [Migration Roadmap](docs/migration-roadmap.md) | Kafka/CDC migration guide |
| [High Scale & Audit](docs/PARTITIONING.md) | Partitioning (pg_partman) & Auditing |

### Observability

| Document | Purpose |
|----------|---------|
| [Observability Guide](docs/observability-guide.md) | Full setup documentation |
| [Grafana Dashboard](docs/grafana-dashboard.json) | Import into Grafana |
| [Prometheus Alerts](docs/prometheus-alerting-rules.yaml) | P1-P4 alerting rules |

## üìú License

MIT ¬© 2024

## ü§ù Contributing

Contributions are welcome! Please read the contributing guidelines first.

---

> **Remember:** This is NOT a message broker. It's a pattern for guaranteed event delivery using PostgreSQL as the source of truth.
